{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1679080120541,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"U6cZzH9SjbJl","outputId":"96dd9d5a-21cf-4449-825d-f4bf868864e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1679080187977,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"m4DyaFsxkQP3","outputId":"9c64cae7-9c02-4e9a-b0e7-dfbed77b4aca"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CSE455 Computer Vision Final Project\n"]}],"source":["cd /content/drive/MyDrive/CSE455 Computer Vision Final Project"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1679080189755,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"CL97b4MtkuON","outputId":"49bba041-40de-420c-e334-f5073ca858a4"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \u001b[0m\u001b[01;34mCombined_Frames\u001b[0m/               'Project Proposal.gdoc'\n"," Farneback_Method.ipynb         'Project timeline.gsheet'\n"," Interpolated.mov                \u001b[01;34mSampleVideo1_Frames\u001b[0m/\n"," Interpolated.mp4                \u001b[01;34mSampleVideo1_Frames_Interpolated\u001b[0m/\n"," InterpolatedSampleVideo1.mov    SampleVideo1.mov\n"," InterpolatedSampleVideo1.mp4    SampleVideo1.mp4\n","'Meeting Notes 3 17 2023.gdoc'   \u001b[01;34mTutorials\u001b[0m/\n","'Meeting Notes.gdoc'             VideoFrameInterpolationWithOpticalFlow.ipynb\n"]}],"source":["ls"]},{"cell_type":"markdown","metadata":{"id":"Kwh8KDUWk1K9"},"source":["# CSE 455 Computer Vision Final Project: Video Frame Rate Interpolation with Farneback Optical Flow\n","## Author: Ciel Sun, Chien Van Le\n","## Date: March 10, 2023\n","## Overview: \n","## This script will perform a video frame interpolation using the technique of optical flow. We will use Lucas Kanade(our own implemenation) and Farneback(cv2 library) optical flow to interpolate the video sequence. The generated video sequence will have a frame rate about twice that of the original/source video sequence(i.e. original frame rate 30fps---\u003e new frame rate 59fps).\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1679081177355,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"dJCS9EQnkzNM"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from google.colab.patches import cv2_imshow\n","\n","from scipy import signal"]},{"cell_type":"markdown","metadata":{"id":"JKVJr94g_QqH"},"source":["# Farneback Optical Flow Implementation"]},{"cell_type":"markdown","metadata":{"id":"XaZp02lOGpLN"},"source":["**Helper Method** \n","This function takes a frame as input, extracts the red, green, and blue channels of the frame using array slicing, and computes the grayscale value using the formula. It then rounds the grayscale value to the nearest integer and converts it to a uint8 data type using NumPy's astype() function. Finally, it returns the grayscale frame."]},{"cell_type":"code","execution_count":124,"metadata":{"executionInfo":{"elapsed":152,"status":"ok","timestamp":1679084794211,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"rv1VEELzCJnB"},"outputs":[],"source":["def cvtColor(frame):\n","    # extract the red, green, and blue channels of the frame\n","    r = frame[:, :, 0]\n","    g = frame[:, :, 1]\n","    b = frame[:, :, 2]\n","\n","    # compute the grayscale value using the formula\n","    gray = 0.299 * r + 0.587 * g + 0.114 * b\n","\n","    # convert the grayscale value to uint8\n","    gray = np.round(gray).astype(np.uint8)\n","\n","    return gray"]},{"cell_type":"markdown","metadata":{"id":"qGzxeBY2G7h6"},"source":["**Helper Method**\n","This function takes an image as input, along with several optional parameters for computing the derivatives. It first creates Sobel filters for computing the horizontal and vertical derivatives, and then applies the filters to the input image using the scipy.signal.convolve2d() function. It then computes the magnitude and orientation of the derivatives using NumPy's sqrt() and arctan2() functions. Finally, it converts the magnitude to the specified data type using NumPy's astype() function, and returns the derivative in the specified direction (horizontal, vertical, or magnitude). You can adjust the optional parameters to get the desired results."]},{"cell_type":"code","execution_count":135,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1679086591545,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"zAeRuPMVDOfw"},"outputs":[],"source":["def sobel(image, ddepth, dx, dy, ksize=3):\n","    # create Sobel filters for computing the derivatives\n","    # sobel_x = np.array([[-1, 0, 1],\n","    #                     [-2, 0, 2],\n","    #                     [-1, 0, 1]])\n","    sobel_s1 = np.array([[1], [2], [1]])\n","    sobel_s2 = np.array([[-1, 0, 1]])\n","    # sobel_y = np.array([[-1, -2, -1],\n","    #                     [0, 0, 0],\n","    #                     [1, 2, 1]])\n","\n","    # compute the horizontal and vertical derivatives using the Sobel filters\n","    fx = signal.convolve2d(image, sobel_s1, mode='same')\n","    fx = signal.convolve2d(fx, sobel_s2, mode='same')\n","    fy = signal.convolve2d(image, sobel_s2.T, mode='same')\n","    fy = signal.convolve2d(fy, sobel_s1.T, mode='same')\n","\n","    # compute the magnitude and orientation of the derivatives\n","    mag = np.sqrt(fx**2 + fy**2)\n","    angle = np.arctan2(fy, fx)\n","\n","    # convert the magnitude to the specified depth\n","    if ddepth == -1:\n","        mag = np.abs(mag)\n","        mag = np.round(mag * 255 / np.max(mag)).astype(np.uint8)\n","    else:\n","        mag = mag.astype(ddepth)\n","\n","    # return the derivative in the specified direction\n","    if dx == 1 and dy == 0:\n","        return fx\n","    elif dx == 0 and dy == 1:\n","        return fy\n","    else:\n","        return mag"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1679086523558,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"5G0ya_3wV8yT","outputId":"bcb65dde-d887-439c-dca4-6e8202773d17"},"outputs":[{"data":{"text/plain":["array([[1, 2, 1]])"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["sx1 = np.array([[1], [2], [1]])\n","sx2 = np.array([[-1, 0, 1]])\n","sx1.T"]},{"cell_type":"markdown","metadata":{"id":"2jehdXHvF32i"},"source":["**Main Method**:\n","This method uses the defined cvtColor() function to convert the frames to grayscale, and the defined Sobel() function to compute the spatial gradients. It then computes the temporal gradient between the two frames by subtracting the grayscale frames, and computes the optical flow vectors using a least-squares solution to the optical flow equation. Finally, it returns the computed flow. You can adjust the optional parameters to get the desired results."]},{"cell_type":"code","execution_count":137,"metadata":{"executionInfo":{"elapsed":164,"status":"ok","timestamp":1679086625052,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"l6MIpnaqAdfm"},"outputs":[],"source":["def calcOpticalFlowLucasKanade(prev_frame, next_frame, pyr_scale=0.5, levels=3, winsize=15, iterations=3,\n","                             poly_n=5, poly_sigma=1.2, flags=0):\n","    # convert frames to grayscale\n","    prev_gray = cvtColor(prev_frame)\n","    next_gray = cvtColor(next_frame)\n","    \n","    # compute the spatial gradients\n","    fx = sobel(prev_gray, -1, 1, 0, ksize=3)\n","    fy = sobel(prev_gray, -1, 0, 1, ksize=3)\n","    \n","    # compute the temporal gradient\n","    ft = next_gray - prev_gray\n","    \n","    # compute the optical flow vectors\n","    flow = np.zeros((prev_gray.shape[0], prev_gray.shape[1], 2))\n","    for i in range(prev_gray.shape[0]):\n","        for j in range(prev_gray.shape[1]):\n","            A = np.array([[np.sum(fx[i,j]**2), np.sum(fx[i,j]*fy[i,j])],\n","                          [np.sum(fx[i,j]*fy[i,j]), np.sum(fy[i,j]**2)]])\n","            b = -np.array([np.sum(fx[i,j]*ft[i,j]), np.sum(fy[i,j]*ft[i,j])])\n","            # d = np.linalg.solve(A + noise, b)  # Adding noise to avoid having correlated columns in A\n","            \n","            noise = np.array([[0.0001, 0], [0, 0.0001]])\n","            v = np.linalg.solve(A + noise, b)  # Adding noise to avoid having correlated columns in A\n","            flow[i,j] = v\n","    return flow"]},{"cell_type":"markdown","metadata":{"id":"C_VyZzIPIxxl"},"source":["References: \n","\n","https://theailearner.com/tag/cv2-sobel/\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html\n","\n","https://www.geeksforgeeks.org/python-opencv-cv2-cvtcolor-method/\n","\n","https://docs.opencv.org/3.4/dc/d6b/group__video__track.html\n","\n","https://www.geeksforgeeks.org/opencv-the-gunnar-farneback-optical-flow/\n","\n","Two-Frame Motion Estimation Based on\n","Polynomial Expansion:\n","\n","http://www.diva-portal.org/smash/get/diva2:273847/fulltext01.pdf"]},{"cell_type":"markdown","metadata":{"id":"VYFc1Q-w_j1W"},"source":["# Video Interpolatio"]},{"cell_type":"markdown","metadata":{"id":"IGcPC8cBS47V"},"source":["## 1. Decompose a video sequence into individual frame images"]},{"cell_type":"code","execution_count":138,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1679086626229,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"X-8lCxqip_sd","outputId":"ebbc5c06-e8b6-4e52-e36a-73b0818bbb43"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \u001b[0m\u001b[01;34mCombined_Frames\u001b[0m/               'Project Proposal.gdoc'\n","'CSE455 Final Project.gslides'  'Project timeline.gsheet'\n"," Farneback_Method.ipynb          \u001b[01;34mSampleVideo1_Frames\u001b[0m/\n"," Interpolated.mov                \u001b[01;34mSampleVideo1_Frames_Interpolated\u001b[0m/\n"," Interpolated.mp4                SampleVideo1.mov\n"," InterpolatedSampleVideo1.mov    SampleVideo1.mp4\n"," InterpolatedSampleVideo1.mp4    \u001b[01;34mTutorials\u001b[0m/\n","'Meeting Notes 3 17 2023.gdoc'   VideoFrameInterpolationWithOpticalFlow.ipynb\n","'Meeting Notes.gdoc'\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":139,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1679086626229,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"sjXjZZQZv1UF","outputId":"26ab2695-7e69-4a07-eb72-c73548464e77"},"outputs":[{"name":"stdout","output_type":"stream","text":["175 frames decomposed from video SampleVideo1.mp4\n","Original frame rate is 25.0 fps\n"]}],"source":["im_path = \"SampleVideo1_Frames\"\n","if not os.path.exists(im_path):\n","  os.mkdir(im_path)\n","video_name = \"SampleVideo1.mp4\"\n","capture = cv2.VideoCapture(video_name)\n","\n","success, frame1 = capture.read()\n","count = 1                                                                       # starting with \"frame1.jpg\"\n","if success: cv2.imwrite(im_path + f\"/frame{count}-0.jpg\", frame1)               # i.e. 'frame1-0.jpg', 'frame2-0.jpg'\n","fps_og = capture.get(cv2.CAP_PROP_FPS)                                          # original frame rate per second 25\n","# while success:\n","#   success, im = capture.read()\n","#   if success:\n","#     count += 1\n","#     cv2.imwrite(im_path + f\"/frame{count}-0.jpg\", im)                           # frames are saved as JPEG files\n","#     if cv2.waitKey(10) == 27:                                                 # exit if Escape is hit\n","#       break\n","totalFrames = len(os.listdir(im_path))\n","print(f'{totalFrames} frames decomposed from video {video_name}')\n","print(f'Original frame rate is {fps_og} fps')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0ouSAFifc3pK"},"source":["## 2. Generate interpolated frames"]},{"cell_type":"code","execution_count":140,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1679086626508,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"9AjxCpQKc9y8"},"outputs":[],"source":["def interpolate(prvs, next, method = 'LucasKanade'):\n","  '''\n","  Generate and return a mid frame based on Farneback opitcal flow of the previous frame and next frame\n","  Parameters:\n","    prvs: previous frame as ndarray with BGR format\n","    next: next frame as ndarray with BGR format\n","  Return:\n","    mid_frame: generated middle frame between previous and next frame\n","  '''\n","  y_max = prvs.shape[0] - 1\n","  x_max = prvs.shape[1] - 1\n","  prvs_gray = cv2.cvtColor(prvs, cv2.COLOR_BGR2GRAY)\n","  next_gray = cv2.cvtColor(next, cv2.COLOR_BGR2GRAY)\n","  # Use gray images to calculate flow with dimension: n x m x 2; 2 channels:[dx/dt, dy/dt]\n","  if method == 'Farneback':\n","    flow = cv2.calcOpticalFlowFarneback(prvs_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)          # farneback optical flow from cv2\n","  else:\n","    flow = calcOpticalFlowLucasKanade(prvs, next, pyr_scale=0.5, levels=3, winsize=15, iterations=3,\n","                             poly_n=5, poly_sigma=1.2, flags=0)                                        # our own implementation of Farneback optical flow\n","  mid_frame = prvs.copy()\n","  for y, row in enumerate(prvs):\n","    for x, col in enumerate(row):\n","      for z, pixVal in enumerate(col):\n","        new_y = y + int(flow[y, x, 1])\n","        new_x = x + int(flow[y, x, 0])\n","        new_y = new_y if new_y \u003c y_max else y_max\n","        new_x = new_x if new_x \u003c x_max else x_max\n","        mid_frame[y, x, z] = prvs[new_y, new_x, z]\n","  return mid_frame"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1679086626685,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"nPzTQWPRHedw","outputId":"2ca87430-a992-4432-f640-85d6c11286d4"},"outputs":[{"data":{"text/plain":["array([0., 0.])"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["# Test Block\n","a1 = np.array([[46656, 46656], [46656, 46656]]) + np.array([[0.0001, 0], [0, 0.0001]])\n","a2 = np.array([0, 0])\n","asolve = np.linalg.solve(a1, a2)\n","asolve\n"]},{"cell_type":"code","execution_count":143,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1679087361162,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"iLOpNZm_A5I_"},"outputs":[],"source":["# # Test block\n","# testFrame1 = frame1\n","# testFrame2 = cv2.imread('/content/drive/MyDrive/CSE455 Computer Vision Final Project/SampleVideo1_Frames/frame2-0.jpg')\n","# # cv2_imshow(testFrame1)\n","# # cv2_imshow(testFrame1)\n","# test_mid = interpolate(testFrame1, testFrame2)\n","# cv2_imshow(test_mid)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1r0-wK1FQmEH"},"outputs":[],"source":["from natsort import natsorted, ns\n","file_list = natsorted(os.listdir(im_path))\n","\n","out_path = im_path + \"_Interpolated_LucasKanade\"                                            # a path storing all interpolated frames\n","if not os.path.exists(out_path):\n","  os.mkdir(out_path)\n","\n","for i in range(len(file_list) - 1):                                             # stop at the second last frame\n","# for i in range(3):\n","  prvs = cv2.imread(im_path + \"/\" + file_list[i])\n","  next = cv2.imread(im_path + \"/\" + file_list[i+1])\n","  mid_frame = interpolate(prvs, next)\n","  cv2.imwrite(out_path + f\"/frame{i+1}-1.jpg\", mid_frame)                       # i.e. 'frame1-1.jpg','frame2-1.jpg'...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QkSBZYf2c-Rz"},"outputs":[],"source":["out_path = im_path + \"_Interpolated_LucasKanade\""]},{"cell_type":"markdown","metadata":{"id":"ED4MlUozdLQF"},"source":["## 3. Compose the original frames and interpolated frames back into one video sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1678704871875,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"DH0Af5qemMrj","outputId":"01058aeb-578e-437b-9201-92af5206ca4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘Combined_Frames’: File exists\n"]}],"source":["mkdir Combined_Frames_LK"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zeum6Qp8ic22"},"outputs":[],"source":["cp SampleVideo1_Frames_Interpolated_LucasKanade/*.jpg Combined_Frames_LK"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjoZ4FLBl3ZR"},"outputs":[],"source":["cp SampleVideo1_Frames/*.jpg Combined_Frames_LK"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1678708277973,"user":{"displayName":"Ciel Sun","userId":"09093071258923760794"},"user_tz":420},"id":"nv2vvDqHc3Be","outputId":"adf57a74-5afe-4b92-cc34-c31bd282ff79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original number of frames:175\n","Number of frames generated: 174\n","Total number of frames: 349\n"]}],"source":["# Origianl frames and interpolation frames are both copied to directory \"Combined_Frames\"\n","interpolate_list = os.listdir(out_path)\n","combine_path = \"Combined_Frames_LK\"\n","combine_list = natsorted(os.listdir(\"Combined_Frames_LK\"))\n","print(f\"Original number of frames: {len(file_list)}\")\n","print(f\"Number of frames generated: {len(interpolate_list)}\")\n","print(f\"Total number of frames: {len(combine_list)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heIuEPUEYeVf"},"outputs":[],"source":["im_arr = []\n","h, w, c = frame1.shape\n","size = (w, h)\n","for fname in combine_list:\n","  im_path = os.path.join(combine_path, fname)\n","  im = cv2.imread(im_path)\n","  im_arr.append(im)\n","\n","output = cv2.VideoWriter(f\"Interpolated_LK_fps{2*fps_og}\"+video_name, \n","                         cv2.VideoWriter_fourcc(*'MP4V'),\n","                         2*fps_og, size)\n","for image in im_arr:\n","  output.write(image)\n","output.release()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP5Ja0iB1wX9ba3k9zdx0z7","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}